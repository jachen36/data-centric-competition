{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70a5b82-e78e-4909-a2f5-c0cb808609df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4fd4a8-4477-4464-8d73-d51340d44f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nfrom local_lib import utils, train\\nfrom pathlib import Path\\nimport random\\nimport shutil\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nfrom local_lib import utils, train\\nfrom pathlib import Path\\nimport random\\nimport shutil\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from local_lib import utils, train\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3fd72b-e9cd-4613-a26e-84f7d52c33ca",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "See the result of simple model runs and how it relates with the private leader board. It is important to see how closely the local validation set actually match with the test set because I can test more iteration than the restrictive 5 times a week competition rule. \n",
    "\n",
    "# Method\n",
    "\n",
    "1. Repeat the baseline model\n",
    "1. Just run the model with clean dataset. \n",
    "1. Train with nonsensical images removed. \n",
    "1. Train with nonsensical images removed and upsample to 10,000. \n",
    "\n",
    "# Conclusion\n",
    "\n",
    "\n",
    "# Future\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab2adaf-1295-477d-86d1-de989b1033b2",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1dde7a1-cbb6-450e-88e6-48b05b020b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"labels_pt = \\\"../data/processed/labels_v0.1.0.csv\\\"\\nsource_image_dir = Path('../data/processed/labeling/images')\\ntrain_image_dir = Path('../data/processed/tmp_training')\\n\\nlabels = pd.read_csv(labels_pt)\";\n",
       "                var nbb_formatted_code = \"labels_pt = \\\"../data/processed/labels_v0.1.0.csv\\\"\\nsource_image_dir = Path(\\\"../data/processed/labeling/images\\\")\\ntrain_image_dir = Path(\\\"../data/processed/tmp_training\\\")\\n\\nlabels = pd.read_csv(labels_pt)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_pt = \"../data/processed/labels_v0.1.0.csv\"\n",
    "source_image_dir = Path('../data/processed/labeling/images')\n",
    "train_image_dir = Path('../data/processed/tmp_training')\n",
    "\n",
    "labels = pd.read_csv(labels_pt)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94f6a4-39f0-4955-88b1-587403e9749b",
   "metadata": {},
   "source": [
    "# Baseline Training\n",
    "\n",
    "The official baseline performance on the public leader board with the original data is `0.65521`.\n",
    "\n",
    "We can see that the validation and the leader board metric is very close to each other which suggestion that the validation is representative of the leaderboard so we don't need to adjust the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501f445-f024-457d-bb71-fd5445271571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if train_image_dir.exists():\n",
    "    shutil.rmtree(train_image_dir)\n",
    "\n",
    "_ = utils.copy_group_to_dir(\n",
    "    df=labels, \n",
    "    source_dir=source_image_dir, \n",
    "    dest_dir=train_image_dir, \n",
    "    group= [\"org_source\", \"org_symbol\"]\n",
    "   )\n",
    "assert len(_) == 0\n",
    "\n",
    "train.train_model(train_image_dir, \"../data/raw/label_book\", verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830524f-1d11-4f00-990d-9523a5f19004",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 100/100\n",
    "259/259 [==============================] - 35s 134ms/step - loss: 0.0242 - accuracy: 0.9942 - val_loss: 1.6930 - val_accuracy: 0.6458\n",
    "102/102 [==============================] - 3s 25ms/step - loss: 1.3684 - accuracy: 0.6814\n",
    "7/7 [==============================] - 0s 31ms/step - loss: 2.7221 - accuracy: 0.5577\n",
    "final loss 1.3684338331222534, final acc 0.6814268231391907\n",
    "test loss 2.722132444381714, test acc 0.557692289352417\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf60599-c8cc-424a-84e4-df180b042502",
   "metadata": {},
   "source": [
    "# Basic data cleaning\n",
    "\n",
    "Relabled the whole dataset which hopefully is a much cleaner dataset. Only `18` out of `813` images were corrected, so the data so the validation was relatively clean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdfdd1c9-c6ab-4347-a904-1b2d50ee8653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"clean_val = labels.query(\\\"org_source == 'val' and org_symbol != symbol\\\")\";\n",
       "                var nbb_formatted_code = \"clean_val = labels.query(\\\"org_source == 'val' and org_symbol != symbol\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_val = labels.query(\"org_source == 'val' and org_symbol != symbol\")\n",
    "clean_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a51c38-64f2-4fc8-9ae2-57e2cb940db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if train_image_dir.exists():\n",
    "    shutil.rmtree(train_image_dir)\n",
    "\n",
    "_ = utils.copy_group_to_dir(\n",
    "    df=labels, \n",
    "    source_dir=source_image_dir, \n",
    "    dest_dir=train_image_dir, \n",
    "    group= [\"org_source\", \"symbol\"]\n",
    "   )\n",
    "assert len(_) == 0\n",
    "\n",
    "train.train_model(train_image_dir, \"../data/raw/label_book\", verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b91fc56-a529-4c30-800e-2dc39ab12179",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 100/100\n",
    "259/259 [==============================] - 40s 152ms/step - loss: 0.0200 - accuracy: 0.9961 - val_loss: 1.5971 - val_accuracy: 0.6507\n",
    "102/102 [==============================] - 2s 22ms/step - loss: 1.1378 - accuracy: 0.7171\n",
    "7/7 [==============================] - 0s 19ms/step - loss: 2.2028 - accuracy: 0.6346\n",
    "final loss 1.1377620697021484, final acc 0.7170971632003784\n",
    "test loss 2.202808141708374, test acc 0.6346153616905212\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15ff36-06c0-4905-b024-02f2f01516f8",
   "metadata": {},
   "source": [
    "# Baseline train with simple augmentations and upsampling up to 10,000 images\n",
    "\n",
    "10,000 is the maximum amount of images allow for the competition. This is the sum of train and validation. \n",
    "\n",
    "nonsensical images were removed before augmentation because augmenting them will provide little or detrimental results to the training since they are noise. \n",
    "\n",
    "The overall performance when from `0.65521` to `0.75000`! However, the validation set metrics has wider gap from the leaderboard than the baseline model. It could be because I am using the \"cleaned\" dataset, but the actual change is relatively small and won't impact the metrics that much. Further investgiation is needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de3b5ac-3692-4ebb-b953-03471965a08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"max_images = 10_000 - 8\\nremainder = max_images - len(labels)\\n\\nif train_image_dir.exists():\\n    shutil.rmtree(train_image_dir)\\n\\n_ = utils.copy_group_to_dir(\\n    df=labels, \\n    source_dir=source_image_dir, \\n    dest_dir=train_image_dir, \\n    group= [\\\"org_source\\\", \\\"symbol\\\"]\\n   )\\nassert len(_) == 0\\n\\nlabels_filtered = labels.query(\\\"suggestion != 'remove' and org_source != 'val'\\\")\\nimages_2_aug = labels_filtered.query(\\\"confusing == 'none' and org_source != 'val'\\\").copy()\\n\\nimages_2_aug[\\\"aug_amount\\\"] = 0\\n\\nimages_per_group = remainder // 10\\n\\nsymbol_counts = images_2_aug.symbol.value_counts()\\n\\n# balance sampling so we don't bias toward common symbols\\nfor row in symbol_counts.to_frame().reset_index().itertuples():\\n    \\n    symbol_sample_min = int(images_per_group/row.symbol)\\n    sample_amount = [symbol_sample_min] * row.symbol\\n    sample_remainder = images_per_group - sum(sample_amount)\\n    if sample_remainder > 0:\\n        sample_amount[:sample_remainder] = [symbol_sample_min + 1] * sample_remainder\\n    random.shuffle(sample_amount)\\n    images_2_aug.loc[images_2_aug.symbol == row.index, \\\"aug_amount\\\"] = sample_amount\\n\\nassert images_2_aug.aug_amount.sum() <= remainder\";\n",
       "                var nbb_formatted_code = \"max_images = 10_000 - 8\\nremainder = max_images - len(labels)\\n\\nif train_image_dir.exists():\\n    shutil.rmtree(train_image_dir)\\n\\n_ = utils.copy_group_to_dir(\\n    df=labels,\\n    source_dir=source_image_dir,\\n    dest_dir=train_image_dir,\\n    group=[\\\"org_source\\\", \\\"symbol\\\"],\\n)\\nassert len(_) == 0\\n\\nlabels_filtered = labels.query(\\\"suggestion != 'remove' and org_source != 'val'\\\")\\nimages_2_aug = labels_filtered.query(\\n    \\\"confusing == 'none' and org_source != 'val'\\\"\\n).copy()\\n\\nimages_2_aug[\\\"aug_amount\\\"] = 0\\n\\nimages_per_group = remainder // 10\\n\\nsymbol_counts = images_2_aug.symbol.value_counts()\\n\\n# balance sampling so we don't bias toward common symbols\\nfor row in symbol_counts.to_frame().reset_index().itertuples():\\n\\n    symbol_sample_min = int(images_per_group / row.symbol)\\n    sample_amount = [symbol_sample_min] * row.symbol\\n    sample_remainder = images_per_group - sum(sample_amount)\\n    if sample_remainder > 0:\\n        sample_amount[:sample_remainder] = [symbol_sample_min + 1] * sample_remainder\\n    random.shuffle(sample_amount)\\n    images_2_aug.loc[images_2_aug.symbol == row.index, \\\"aug_amount\\\"] = sample_amount\\n\\nassert images_2_aug.aug_amount.sum() <= remainder\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_images = 10_000 - 8\n",
    "remainder = max_images - len(labels)\n",
    "\n",
    "if train_image_dir.exists():\n",
    "    shutil.rmtree(train_image_dir)\n",
    "\n",
    "_ = utils.copy_group_to_dir(\n",
    "    df=labels, \n",
    "    source_dir=source_image_dir, \n",
    "    dest_dir=train_image_dir, \n",
    "    group= [\"org_source\", \"symbol\"]\n",
    "   )\n",
    "assert len(_) == 0\n",
    "\n",
    "labels_filtered = labels.query(\"suggestion != 'remove' and org_source != 'val'\")\n",
    "images_2_aug = labels_filtered.query(\"confusing == 'none' and org_source != 'val'\").copy()\n",
    "\n",
    "images_2_aug[\"aug_amount\"] = 0\n",
    "\n",
    "images_per_group = remainder // 10\n",
    "\n",
    "symbol_counts = images_2_aug.symbol.value_counts()\n",
    "\n",
    "# balance sampling so we don't bias toward common symbols\n",
    "for row in symbol_counts.to_frame().reset_index().itertuples():\n",
    "    \n",
    "    symbol_sample_min = int(images_per_group/row.symbol)\n",
    "    sample_amount = [symbol_sample_min] * row.symbol\n",
    "    sample_remainder = images_per_group - sum(sample_amount)\n",
    "    if sample_remainder > 0:\n",
    "        sample_amount[:sample_remainder] = [symbol_sample_min + 1] * sample_remainder\n",
    "    random.shuffle(sample_amount)\n",
    "    images_2_aug.loc[images_2_aug.symbol == row.index, \"aug_amount\"] = sample_amount\n",
    "\n",
    "assert images_2_aug.aug_amount.sum() <= remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d29ec-eabc-4239-9030-dfa5e02be50c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Crop(px=(1, 16), keep_size=True),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0))\n",
    "])\n",
    "\n",
    "utils.apply_aug(images_2_aug, source_image_dir, train_image_dir, seq, [\"org_source\", \"symbol\"])\n",
    "\n",
    "train.train_model(train_image_dir, \"../data/raw/label_book\", verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c1572-784b-4692-8d00-2d1bf13f85ed",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 100/100\n",
    "1148/1148 [==============================] - 147s 128ms/step - loss: 0.0220 - accuracy: 0.9926 - val_loss: 1.3617 - val_accuracy: 0.7306\n",
    "102/102 [==============================] - 2s 21ms/step - loss: 0.9264 - accuracy: 0.8118\n",
    "7/7 [==============================] - 0s 29ms/step - loss: 1.7896 - accuracy: 0.7115\n",
    "final loss 0.9263656139373779, final acc 0.8118081092834473\n",
    "test loss 1.7895989418029785, test acc 0.7115384340286255\n",
    "```\n",
    "\n",
    "Leader board result  \n",
    "\n",
    "Aug 12 - submission-01 = 0.75000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e9414c-bdea-4fb5-9fd7-77c4e7c33aa0",
   "metadata": {},
   "source": [
    "## Train with nonsensical image removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789da97-0596-4e91-b73e-a327da2669af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_filtered = labels.query(\"suggestion != 'remove' or org_source == 'val'\")\n",
    "\n",
    "if train_image_dir.exists():\n",
    "    shutil.rmtree(train_image_dir)\n",
    "\n",
    "_ = utils.copy_group_to_dir(\n",
    "    df=labels_filtered, \n",
    "    source_dir=source_image_dir, \n",
    "    dest_dir=train_image_dir, \n",
    "    group= [\"org_source\", \"symbol\"]\n",
    "   )\n",
    "assert len(_) == labels.query(\"suggestion == 'remove' and org_source == 'train'\").shape[0]\n",
    "\n",
    "train.train_model(train_image_dir, \"../data/raw/label_book\", verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fb295d-84c2-40a1-81f0-dd6af93767a6",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 100/100\n",
    "249/249 [==============================] - 36s 145ms/step - loss: 0.0172 - accuracy: 0.9955 - val_loss: 1.4800 - val_accuracy: 0.6851\n",
    "102/102 [==============================] - 3s 27ms/step - loss: 1.1938 - accuracy: 0.7319\n",
    "7/7 [==============================] - 0s 23ms/step - loss: 1.8671 - accuracy: 0.5577\n",
    "final loss 1.1938356161117554, final acc 0.7318572998046875\n",
    "test loss 1.8670954704284668, test acc 0.557692289352417\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c0d3b-1cf2-4cc9-bd35-2ee9b86339f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce562f06-8c98-409d-bdc6-1b5e5f6870ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
